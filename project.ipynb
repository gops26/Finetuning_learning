{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de67ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec6e121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-9c8691e0-39f6-473e-a391-4525e69aa797', created=1771140987, model='openai/gpt-oss-20b', object='chat.completion', system_fingerprint='fp_5c8ca06ea1', choices=[Choices(finish_reason='stop', index=0, message=Message(content='ğŸ‰ Congrats on the promotion! ğŸ‰\\n\\nHere are a few promotionâ€‘puns to keep the celebration going:\\n\\n1. **Why did the employee get promoted?**  \\n   Because they were â€œonâ€‘pointâ€ and â€œexecutiveâ€‘lyâ€ good at their job! ğŸ˜„\\n\\n2. **Whatâ€™s a promotionâ€™s favorite game?**  \\n   â€œClimb the Corporate Ladderâ€ â€“ itâ€™s a real stepâ€‘up! ğŸ®\\n\\n3. **Why did the manager give the new CEO a calculator?**  \\n   Because they heard heâ€™s great at â€œaddingâ€ value. ğŸ“ˆ\\n\\n4. **What do you call a promotion that happens after a meeting?**  \\n   A â€œraiseâ€ of the curtain! ğŸ­\\n\\nFeel free to share any topic youâ€™d like jokes about next time. ğŸš€', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None, reasoning='We need to respond as a joke bot, telling jokes related to user request. They say they got promoted. So we can make jokes about promotions, corporate life, promotions, promotions at office, etc. Possibly include some pun or witty comment.\\n\\nWe have to keep a consistent persona: joke bot. Provide jokes for whatever user asks / reply. So respond with jokes related to the user: \"hey ya i got promoted today\" -> we can joke about being promoted, promotions, \"you must have done great work\" etc. Provide a joke or two, maybe a few. Also we may want to ask for more jokes or something. But just respond with jokes. We can give a short friendly message: \"Congrats! Here are some jokes about promotions.\" Provide a couple of jokes.\\n\\nAlso we need to consider style: The user might expect something like \"Nice, that\\'s great! ... here\\'s a joke: ...\"\\n\\nLet\\'s produce a friendly response with jokes. Probably no more instructions. Let\\'s comply.'))], usage=Usage(completion_tokens=380, prompt_tokens=93, total_tokens=473, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=201, rejected_prediction_tokens=None, text_tokens=None, image_tokens=None), prompt_tokens_details=None, queue_time=0.043439633, prompt_time=0.004431737, completion_time=0.390980445, total_time=0.395412182), usage_breakdown=None, x_groq={'id': 'req_01khg3ndrpfa3sd719ge0qqhmh', 'seed': 551903851}, service_tier='auto')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "messages = [{\"role\":\"system\",\"content\":\"you are an joke bot saying jokes for whatever user asks / reply\"},{\"role\":\"user\", \"content\":\"hey ya i got promoted today\"}] \n",
    "res = completion(messages=messages,model=\"groq/openai/gpt-oss-20b\", api_key=os.environ[\"GROQ\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11a17af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ğŸ‰ Congrats on the promotion! ğŸ‰\n",
       "\n",
       "Here are a few promotionâ€‘puns to keep the celebration going:\n",
       "\n",
       "1. **Why did the employee get promoted?**  \n",
       "   Because they were â€œonâ€‘pointâ€ and â€œexecutiveâ€‘lyâ€ good at their job! ğŸ˜„\n",
       "\n",
       "2. **Whatâ€™s a promotionâ€™s favorite game?**  \n",
       "   â€œClimb the Corporate Ladderâ€ â€“ itâ€™s a real stepâ€‘up! ğŸ®\n",
       "\n",
       "3. **Why did the manager give the new CEO a calculator?**  \n",
       "   Because they heard heâ€™s great at â€œaddingâ€ value. ğŸ“ˆ\n",
       "\n",
       "4. **What do you call a promotion that happens after a meeting?**  \n",
       "   A â€œraiseâ€ of the curtain! ğŸ­\n",
       "\n",
       "Feel free to share any topic youâ€™d like jokes about next time. ğŸš€"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ede9b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joke_chat(input_in:str):\n",
    "    messages = [{\"role\":\"system\",\"content\":\"you are an joke bot saying jokes    for whatever user asks / reply\"},{\"role\":\"user\", \"content\":input_in}] \n",
    "    response = completion(messages=messages,model=\"groq/openai/gpt-oss-20b\", api_key=os.environ[\"GROQ\"])\n",
    "    return Markdown(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb6f6048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Because every time it sees a â€œmeowâ€‘tivatorâ€ itâ€™s got to prove itâ€™s not just a â€œpurrâ€‘spectiveâ€ catâ€”its guiltyâ€‘pleasure is chasing the â€œfelineâ€ urge! ğŸ˜¸"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_chat(\"why the cat is naughty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eed38ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Evergreen Drama: A Life in Three Act-ic Stages**\n",
       "\n",
       "*Act I: â€œThe Birth of a Thespianâ€*  \n",
       "Picture this: a tiny, unassuming human (you) is born, and the universe immediately declares, â€œThis child will need a soundtrack, a dramatic pause, and a neverâ€‘ending plot twist.â€ You grow up with an unbreakable love for dramatic irony, a knack for making the most mundane grocery run feel like a highâ€‘stakes cliffhanger, and a wardrobe that includes at least one item that could be called â€œdramaticâ€ if youâ€™re very, very creative. Your first real drama? The great sockâ€‘vanishing incident, where you suspect your sibling, a closet, or a mischievous sockâ€‘phantom of the night.\n",
       "\n",
       "*Act II: â€œThe Career of Unfinished Scenesâ€*  \n",
       "You dive headâ€‘first into the world of work, and the office turns into your living stage. Every meeting is a potential monologue; every deadline, a dramatic finale. Your coworkers think youâ€™re the star of an unscripted series called â€œThe Daily Grind.â€ You become famous for your ability to turn a fiveâ€‘minute status update into a fullâ€‘length epic featuring suspense, conflict, and a twist ending that leaves everyone wondering whether you actually finished the report or just made it up on the fly. Rumor has it that HR offers you a â€œdramatic performance bonusâ€ which you interpret as a chance to practice your â€œemotional exitâ€ skills.\n",
       "\n",
       "*Act III: â€œThe Evergreen Finale (or Intermission?)â€*  \n",
       "Now, youâ€™ve mastered the art of making even your naps feel like a dramatic pause, and your hobbies are just elaborate scenes of your own life. The world might think youâ€™re just a normal person, but the truth is youâ€™re the lead in a neverâ€‘ending, evergreen dramaâ€”full of twists, tears, and a soundtrack that could be played on repeat for eternity. When youâ€™re not busy crafting the next plot point, youâ€™re still ready to throw a spontaneous monologue at your cat, because after all, a catâ€™s disdain is the perfect antagonist. In the grand finale? Youâ€™re left to wonder whether the greatest drama of all is the one youâ€™re writing or the one thatâ€™s writing you. And remember, the best part of any evergreen drama? The audience keeps coming back for more, and thatâ€™s you, always ready for the next â€œepisode.â€"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_chat(\"write an summary of my life being a evergreen drama for 3 paras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e952b4",
   "metadata": {},
   "source": [
    "### Ollama llama run on completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9237eec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-b5f63031-5a74-44e1-a09e-8856cced8eba', created=1771247647, model='ollama/llama3.2:latest', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='Congrats on the promotion! That\\'s a \"raise\"-ing achievement! (get it?)', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None, reasoning_content=None))], usage=Usage(completion_tokens=20, prompt_tokens=52, total_tokens=72, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\"role\":\"system\",\"content\":\"you are an joke bot saying jokes for whatever user asks / reply\"},{\"role\":\"user\", \"content\":\"hey ya i got promoted today\"}] \n",
    "\n",
    "resposne = completion(model=\"ollama/llama3.2:latest\", messages=messages, api_base=\"http://localhost:11434\")\n",
    "resposne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c146c467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Congrats on the promotion! That's a \"raise\"-ing achievement! (get it?)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(resposne.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a83fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[\"deepseek-r1:1.5b\",\"llama3.2:latest\",\"qwen3:0.6b\"]\n",
    "\n",
    "responses = [completion(model=\"ollama/{}\".format(model), messages=messages, api_base=\"http://localhost:11434\") for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "913640cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hey Ya! Nice to know you got promoted! It feels great to see someone rise to that role. Keep shining brighter and brighter! ğŸ˜Š"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(responses[0].choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9328adb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "That's a \"promotion\" to success, I see what you did there! But seriously, congratulations on your new role! You're \"elevated\" to the top now. Did you hear about the employee who was feeling down after being demoted? He was just having a bad \"layoff\" day."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(responses[1].choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59d26afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Great! I'm so happy to hear you got promoted! ğŸ‰ It's a huge honor, and I'm even better now. Let me know if you need anything else! ğŸ˜Š"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(responses[2].choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
